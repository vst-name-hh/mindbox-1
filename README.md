# Документация
## Задание
[Оригинальное задание(в репо)](docs/test.md)

[Оригинальное задание(Google)](https://docs.google.com/document/d/1Zl7Fj3HgLqc8Ecs_-W209S9UrpIbkji1_rgU9oK3jVU/)

## Предположение:
### Инфраструктура:
1. 3 Зоны в мультизональном кластере.
2. 5 Нод на зону.
3. 5-10 Секунд для инициализации.
4. В текущей пиковой нагрузке 4 пода справляются с пиковой нагрузкой.
5. На первые запросы приложению требуется значительно больше ресурсов CPU.
6. В дальнейшем потребление ровное в районе 0.1 Mi CPU. По памяти всегда стабильно в районе 128MiB.
7. Приложение имеет дневной цикл нагрузки – ночью запросов на порядки меньше.
### Приложение:
1. Клиенткое приложение.
2. Потребление ресурсов слабо коррелируется с клиентской нагрузкой.
3. Первоначальный всплеск и постоянная нагрузка в *runtime*, возможно статичный контент?

> Nginx + Загружаемый статичный контент.

> API Endpoint где контент **легковесно**, добывается в *runtime* из другой системы. Например Redis кластеры, или только при инициализации из KV систем, например Consul или Zookeper

4. Долгий start-up time возможно предполагает I.O. задержку, в качестве best-practive предположу безопастность коммуникаций, например:

> Hashicorp vault с k8s токен авторизацией

> S3 Endpoint для статичных файлов

Альтернативно:
> В образ контейнера включен некий архивированный контент, где при запуске контейнера контент распаковывается, например: gzip -9 ?

> JIT

> Внешний Датасет?

5. Всплеск нагруки наблюдается только при первых запросах - по возможности включу в deployment cache pre-warming
6. Возможна допольнительная оптимизация в зависимости от *runtime*, например:
> GOMAXPROCS=1

## Решение

### Мультизональность
1. 3 зоны, предположительно в разных датацентрах/регионах.
В зависимости от конфигурации балансировщика L4/L7, возможна внешняя балансирова посредством DNS Round-Robin, или IP Anycast. Для минимизации межзонального трафика, в качестве best-practice, предположу мин. 1 под на зону.
2. Внутризоны, предположу доступность доступность в минимум 5 нод, в качестве best-practice использую soft pod antiAffinity
3. Предположу сбалансированную/равномерную нагрузку трафика на зону, использую topologySpreadConstraints в **1** под.

### Цикличная нагрузка
1. Встроенные k8s примитивы не имеют возможность масштабирования по времени, будет задействован keda оператор с cron триггером.
2. Для дневной нагрузки, предположу офисные рабочие часы с 9:00 до 18:00.


### Ingress
1. TLS Терминирование на уровне Ingress.
2. Без SVC Mesh.
3. ClientIP либо не необходим, либо может быть передан с HTTP заголовком от Балансировщика.
4. В качестве Ingress-контроллера будет использован внутрикластерный Ingress-Nginx. Все аннотации будут с ним. Managed Kubernetes PaaS Ingress-Controller решения специфичны для каждого отдельного поставщика.
5. В качестве провайдера сертификатов будет использован внутрикластерный Cert-Manager.

### Метрика
1. Вследствии низкой корреляции клиентской нагрузки с требованием к ресурсам, обозреваемость является критичным компонентом для HPA.
2. Предположу что приложение публикует **/metrics endpoint** для сбора метрики, альтернативно возможно использовать метрику внутрикластерного Ingress-контроллера.

### SLO/SLI
1. Keda ScaledObject - HPA
2. PDB 1 под на Зону
3. Keda SO request latency триггер - масштабирование на основе метрики задержки запроса, предположу мин. цель в 100мс в среднем в минуту на под.
4. RequestRate - 5000 HTTP запросов на под в минуту
5. ErrorRate - невозможно расчитать без информации о системе/backend'е, игнорируется.
6. Высокий uptime обеспечивается вышеобозначенной политикой.
7. Предположу что приложение публикует **/health endpoint** для healthCheck Probe.

### FinOps
1. Keda SO минимизирует ресурсы в простое.
2. Минимизация ресурсов обеспечивается с вышеобозначенной политикой.

### ETC
1. Для идентефикации объектов будут использованы рекомендуемые Labels:
> app.kubernetes.io/name

> app.kubernetes.io/component

> app.kubernetes.io/part-of

> topology.kubernetes.io/zone

2. Объекты в основном не имеют обозначенного namespace - для деплоймента через CD или kustomize(кроме promql query в Keda SO)